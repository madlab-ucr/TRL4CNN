{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2130,
     "status": "ok",
     "timestamp": 1658190394627,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "ThJS_9q7F2GW",
    "outputId": "217a630f-0284-4656-aba2-cd47736c0b20"
   },
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch, torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxNPGERyv0_k"
   },
   "source": [
    "### Tensorly Torch TRL Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1658190404013,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "LRHCbFCkF7Kf",
    "outputId": "3aec5b4e-7cb3-4d38-a0fb-d01c2e941f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([1, 5, 3, 2]) torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "input_shape = (5, 3, 2)\n",
    "output_shape = (5,2)\n",
    "batch_size = 1\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "print(device)\n",
    "\n",
    "x = torch.randn((batch_size,) + input_shape,\n",
    "                dtype=torch.float32, device=device)\n",
    "trl = tltorch.TRL(input_shape, output_shape, rank='same')\n",
    "result = trl(x)\n",
    "print(x.shape, result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's like TRL let's you reshape the tensor along all modes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxOhaq0hPCFf"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1658190406467,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "Lsgh9LoFRHuf",
    "outputId": "58738632-4525-4661-af80-1ebcf9caaca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and preprocess CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2313,
     "status": "ok",
     "timestamp": 1658190411384,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "w0Y6gHQIWz8r",
    "outputId": "88a35de9-ac65-4115-fd79-3f1ca5836783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                          std=[0.2023, 0.1994, 0.2010])\n",
    "                                     ])\n",
    "# Create Training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "# Create Testing dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "# Instantiate loader objects to facilitate processing\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1658190418809,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "6ByPQhXjW1fo"
   },
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        self.trl = tltorch.TRL(input_shape=(64, 5, 5), output_shape=(32, 6, 6), rank='same')\n",
    "        self.fc1 = nn.Linear(32*6*6, 128) # 128 is a random choice by me could be anything \n",
    "\n",
    "        # self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.trl(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1658190420185,
     "user": {
      "displayName": "Rutuja Gurav",
      "userId": "08001823661153941951"
     },
     "user_tz": 420
    },
    "id": "2Gy6V-4li_sf",
    "outputId": "fe378c05-23cb-4f4e-a3ae-afd1b4491949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeuralNet(\n",
      "  (conv_layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_layer2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_layer3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv_layer4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (trl): TRL(\n",
      "    (weight): CPTensor(shape=(64, 5, 5, 32, 6, 6), rank=15620)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1152, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNeuralNet(num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# from torchsummary import summary\n",
    "# print(summary(model, (3,32,32)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRxLlPdFjD3F",
    "outputId": "a0a799ff-9446-47f5-ab8e-8570bd0d9e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.7722\n",
      "Epoch [2/2], Loss: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "def train(num_epochs, model, optimizer, lossfn):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        #Load in the data in batches using the train_loader object\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = lossfn(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            epoch_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(sum(epoch_loss)/len(epoch_loss))\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "    return losses\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "total_step = len(train_loader)\n",
    "losses = train(num_epochs, model, optimizer, lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNPMY8OK2zDvjJlU/rEm+sn",
   "collapsed_sections": [],
   "name": "TRL4CNN_WorkInProgress.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.10 ('trl4cnnenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "57af59ae97c77970e7858c0dfe603048217fc630e199e1ab9e990e6bda84fe44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
